{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Hamming Analysis\n",
    "This notebook takes the nucleotide counts produced in step 2, FastQ to Nucleotides and converts them to the amino acid counts while accounting for and subtracting expected error in illumina sequencing, termed Hamming Filtering. \n",
    "\n",
    "Previously in FastQ to Nucleotides (analysis step 2) we threw out any read where the base calls in the coding region (or coding region of the sublibrary of interest, specifically) had a Q score of less than 30. Here we will conservatively assume that every nucleotide has a Q score of 40, or a 0.01% chance of being an errant base call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hamming Analysis, created by James McCormick (in this context) is the process for accounting for the error rate in Illumina sequencing. Because each read is counted as a single mutant, a base call with a quality score Q40 has a 99.99% base call accuracy. But when there are a large number of reads, numbering into the billions for this set of experiments, the contribution of miscalled mutations that are actually wild type (or a mutant that is misread as wild type) becomes an important contribution.\n",
    "\n",
    "This source of noise is also not uniform. If we sequence only an identical wild type sequence with a very large number of reads, apparent mutations that require two adjacent mutations are much less likely than ones that are a single base miscall away. Such as ATG being called falsely as ATC (met to ile) vs ATG to AAC (met to asn). \n",
    "\n",
    "From the Hamming distance Wikipedia article: \"In information theory, the Hamming distance between two strings of equal length is the number of positions at which the corresponding symbols are different. In other words, it measures the minimum number of substitutions required to change one string into the other, or the minimum number of errors that could have transformed one string into the other. In a more general context, the Hamming distance is one of several string metrics for measuring the edit distance between two sequences. It is named after the American mathematician Richard Hamming.\"\n",
    "\n",
    "The probability of two errant base calls happening (a hamming distance of two) is 0.0001 x 0.0001, three errant base calls is 0.0001 x 0.0001 x 0.0001 or P^H where P is the probability of a errant base call and H is the hamming distance. \n",
    "\n",
    "Once we have the probability of an errant mutant stemming from another sequence, we can calculate the number of errant calls we would expect from a given number of other counts, e.g. wild type. If there are 1,000,000 reads of the wild type sequence and mutation A is one hamming distance from wild type, we can estimate that there are (1,000,000*0.0001^1) = 100 mutant A's that are errantly called wild type. We can repeat this for every observed mutation type at that codon. \n",
    "\n",
    "### This process makes a few simplifying assumptions:\n",
    "\n",
    "1. That every other observed mutant/wild type is correct.\n",
    "2. There are no mutants that are misread in one location and then misread again to produce this mutation. \n",
    "    e.g. ATTCGG --> ATCCGA. \n",
    "3. The probability of the sequencer missing a base call is equal to the resultant mutation.\n",
    "    i.e. that an erroneous ATC -> ATG is equally as likely as an erroneous ATC -> ATT\n",
    "4. That every base call has a Q score equal to the average as reported by genewiz \n",
    "    This is not true, and is a source of bias, as the average Q score is better at the start of a read, which is why USEARCH (step 1) and paired end coverage is employed. Scores below Q30 were thrown out in the previous script and USEARCH increases the Q score from that of illumina base calling. \n",
    "    \n",
    "These assumptions result in a \"hard filtering\" where more reads are thrown away than strictly need to be.\n",
    "\n",
    "Error not accounted for: Index Hopping. Where the index is incorrectly assigned. \n",
    "This happens generally and in this library about 1.5% of the time. I can't filter it out and have to live with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from scipy import stats #as stats\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_dna\n",
    "from Bio.SeqUtils import seq3\n",
    "from Bio.SeqUtils import seq1\n",
    "from matplotlib import rcParams\n",
    "from pathlib import Path #introduced in Python 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this set of turbidostat experiments there is no non chimeric protein (DL121 is the wild type)\n",
    "#However the LOV2 insertion is not mutated, and is not sequenced. \n",
    "#the wt sequence of DHFR\n",
    "dhfr_wt = 'MISLIAALAVDRVIGMENAMPWNLPADLAWFKRNTLNKPVIMGRHTWESIGRPLPGRKNIILSSQPGTDDRVTWVKSVDEAIAACGDVPEIMVIGGGRVYEQFLPKAQKLYLTHIDAEVEGDTHFPDYEPDDWESVFSEFHDADAQNSHSYCFEILERR'\n",
    "dhfr_wt_ix = np.arange(len(dhfr_wt[:]))\n",
    "\n",
    "#477 nt long, or 159 residues. WT codon sequence of DHFR\n",
    "dhfr_nuc_wt = 'ATGATCAGTCTGATTGCGGCGTTAGCGGTAGATCGCGTTATCGGCATGGAAAACGCCATGCCGTGGAACCTGCCTGCCGATCTCGCCTGGTTTAAACGCAACACCTTAAATAAACCCGTGATTATGGGCCGCCATACCTGGGAATCGATCGGTCGTCCGTTGCCAGGACGCAAAAATATTATCCTGAGCTCACAACCGGGTACGGACGATCGCGTAACGTGGGTGAAGTCGGTGGATGAAGCAATTGCGGCGTGTGGTGACGTACCAGAAATCATGGTGATTGGCGGCGGCCGCGTTTATGAACAGTTCTTGCCAAAAGCGCAAAAGCTTTATCTGACGCATATCGACGCAGAAGTGGAAGGCGACACCCATTTCCCGGATTACGAGCCGGATGACTGGGAATCGGTATTCAGCGAATTCCACGATGCTGATGCGCAGAACTCTCACAGCTATTGCTTTGAGATTCTGGAGCGGCGG'\n",
    "dhfr_nuc_wt_ix = np.arange(len(dhfr_nuc_wt[:]))\n",
    "\n",
    "#all amino acids (* is stop) \n",
    "aas = 'ACDEFGHIKLMNPQRSTVWY*'\n",
    "aas_ix = np.arange(len(aas[:]))\n",
    "\n",
    "#to build my list of all 64 codons. \n",
    "\n",
    "codon_list = ['GCT', 'GCC', 'GCA', 'GCG', 'CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'AAT', 'AAC', 'GAT', 'GAC', 'TGT', 'TGC'\\\n",
    ", 'CAA', 'CAG', 'GAA', 'GAG', 'GGT', 'GGC', 'GGA', 'GGG', 'CAT', 'CAC', 'ATT', 'ATC', 'ATA'\\\n",
    ", 'CTT', 'CTC', 'CTA', 'CTG', 'TTA', 'TTG', 'AAA', 'AAG', 'ATG', 'TTT', 'TTC', 'CCT', 'CCC', 'CCA', 'CCG'\\\n",
    ", 'TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC', 'ACT', 'ACC', 'ACA', 'ACG', 'TGG', 'TAT', 'TAC'\\\n",
    ", 'GTT', 'GTC', 'GTA', 'GTG', 'TAA', 'TAG', 'TGA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the count of each nucleotide from step 2, DL121_fastq_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing each sample and storing the data in the form of a dictionary\n",
    "\n",
    "#import the counts\n",
    "data_dict = {}\n",
    "path_to_input = Path(\"../Step_2_fastq_to_nucleotides/output/\")\n",
    "#all filenames in masterfile so the selection can be changed quickly\n",
    "filenames = open('masterfile.txt','r').readlines() \n",
    "for filename in filenames: #open the counts in each sample\n",
    "    filename = filename.strip() #removes whitespaces and lines\n",
    "    filepath = path_to_input / filename #gets the absolute path to the previous output files\n",
    "    data = open(filepath,'r').readlines() \n",
    "    filename = filename[:-7]\n",
    "    data_dict[filename] = {} #add sample to the dict that contains all of your data\n",
    "\n",
    "    for line in data: #iterate through each line in the sample\n",
    "        sp_line = line.split('\\t') \n",
    "        if sp_line[0][0:2] != 'SL' and sp_line[0][0:2] != 'CL': #only looks at lines that start with SL/CL\n",
    "            continue #skip over statistics in this file \n",
    "        else: \n",
    "            sl_id = sp_line[0] #save the SL it belongs to\n",
    "            mut = sp_line[1] #determine the mutant \n",
    "            mut_count = sp_line[2] #determine the number of reads for that mutant\n",
    "            \n",
    "            # adds the reads for that mutant to the dictionary and categorizes the SL this datapoint goes to\n",
    "            if sl_id in data_dict[filename].keys(): \n",
    "                data_dict[filename][sl_id][mut] = float(mut_count.strip())\n",
    "            else:\n",
    "                data_dict[filename][sl_id] = {}\n",
    "                data_dict[filename][sl_id][mut] = float(mut_count.strip())\n",
    "#data_dict['T6V2']['SL1']['WT'] #example of how to access the data point in dictionary [sample][sub-lib][mutant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the matrix will have 64 columns and 159 rows\n",
    "full_codon_matrix = np.zeros(shape = [len(dhfr_wt_ix),len(codon_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for going from nucleotides to aa\n",
    "def translate_seq(seq):\n",
    "    seq = Seq(seq,generic_dna)\n",
    "    seq_translate = str(seq.translate().strip())\n",
    "    return seq_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ix_mutant(mut,mut_count,reads_mat,i,j):\n",
    "    \n",
    "    #organizing mutant counts into matricies\n",
    "    #global variables are the matricies of zeros that will store counts for DHFR mutants and mini-library mutants\n",
    "    #local variables will be the mutation id and the counts of this mutant\n",
    "    \n",
    "    if mut in ['WT','fail_multimutant']:\n",
    "        pass\n",
    "    else:\n",
    "        #determine position of the mutant\n",
    "        mut_pos = mut[3:-3] #use name of mutant to pull out the position in DHFR\n",
    "        mut_ix = dhfr_wt_ix[int(mut_pos)-1] #find the ix of the mutant position\n",
    "\n",
    "        #determine position of the aa of the mutation\n",
    "        mut_nuc = mut[-3:] #this gives the nucelotide sequence\n",
    "        #mut_aa = translate_seq(mut_nuc) #converts it into aa\n",
    "        mut_nuc_ix = codon_list.index(mut_nuc)\n",
    "        \n",
    "        #set corresponding position in the matrix to the mutant count! \n",
    "        reads_mat[i,j] = mut_count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use i to signify each of the 159 amino acids of DHFR that have been mutated (all of them) and j to be the 64 different possible codons. Using a series of loops we iterate through every possible codon mutation in DHFR and pull the number observed out from the dictionary. This allows us to convert that information into a matrix. This is done for every timepoint and vial separately. \n",
    "Due to read length restriction for the illumina library the DHFR protein is broken up into 4 sublibraries, each in its own set of wild type counts, hence the SL# used below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to build matrix of all counts. \n",
    "#full_codon_matrix is the size, codon_list is the nucelotide list\n",
    "\n",
    "#if the mutant is not in the dictionary (never seen) it is saved in missing_mut\n",
    "missing_mut = [] \n",
    "\n",
    "#for a non-wildtype ending in A/T (which shouldnt be made by NNS primers), it is saved in wrong_mut\n",
    "#but not converted into the residue count, as it most likely is from sequencing error\n",
    "wrong_mut = []\n",
    "\n",
    "nucleotide_matrix = {}\n",
    "for condition in list(data_dict.keys()):\n",
    "    working_dict = data_dict[condition]\n",
    "    reads_mat = np.zeros(shape = [len(dhfr_wt_ix),len(codon_list)])\n",
    "    i = 0 # Down the matrix (dhfr_wt aas) 0-158\n",
    "    j = 0 # Across the matrix (nucleotides) 0-63\n",
    "    while (i <= 158):\n",
    "        j = 0\n",
    "        while (j <= 63):\n",
    "            ione = (np.multiply(i,3)) #these allow for grabbing wt codon from wt aa sequence position.\n",
    "            itwo = (np.multiply(i,3) +1)\n",
    "            ithree = (np.multiply(i,3) +2)        \n",
    "            #this gives the name in the directory to look up\n",
    "            position_name = (dhfr_nuc_wt[ione]+dhfr_nuc_wt[itwo]+dhfr_nuc_wt[ithree]+str((i+1))+codon_list[j])\n",
    "            if (i < 40): #SL1\n",
    "                sl = 'SL1' #sublibrary one\n",
    "                if (dhfr_nuc_wt[ione]+dhfr_nuc_wt[itwo]+dhfr_nuc_wt[ithree]) == codon_list[j]: #WILD TYPE!\n",
    "                    mut_count = working_dict[sl]['WT']\n",
    "                    ix_mutant(position_name,mut_count,reads_mat,i,j)\n",
    "                    j = j + 1\n",
    "                    continue    \n",
    "                else: #A and T should not show up in NNS mutations and are not counted\n",
    "                    if position_name in working_dict[sl].keys():\n",
    "                        if codon_list[j][-1] == 'A':\n",
    "                            wrong_mut.append(position_name)\n",
    "                            j = j + 1\n",
    "                            continue\n",
    "                        elif codon_list[j][-1] == 'T':\n",
    "                            wrong_mut.append(position_name)\n",
    "                            j = j + 1\n",
    "                            continue                          \n",
    "                        else:\n",
    "                            mut_count = working_dict[sl][position_name]\n",
    "                            ix_mutant(position_name,mut_count,reads_mat,i,j)\n",
    "                            j = j + 1\n",
    "                            continue \n",
    "                    else:\n",
    "                        missing_mut.append(position_name)\n",
    "                        j = j + 1\n",
    "                        continue \n",
    "            elif (i >= 40) and (i < 80): #SL2\n",
    "                sl = 'SL2' #sublibrary two\n",
    "                #cheeck if the mutant matches the wild type sequence\n",
    "                if (dhfr_nuc_wt[ione]+dhfr_nuc_wt[itwo]+dhfr_nuc_wt[ithree]) == codon_list[j]: #WILD TYPE!\n",
    "                    mut_count = working_dict[sl]['WT']\n",
    "                    ix_mutant(position_name,mut_count,reads_mat,i,j)\n",
    "                    j = j + 1\n",
    "                    continue    \n",
    "                else: #A and T should not show up in NNS mutations and are not counted\n",
    "                    if position_name in working_dict[sl].keys():\n",
    "                        if codon_list[j][-1] == 'A':\n",
    "                            wrong_mut.append(position_name)\n",
    "                            j = j + 1\n",
    "                            continue\n",
    "                        elif codon_list[j][-1] == 'T':\n",
    "                            wrong_mut.append(position_name)\n",
    "                            j = j + 1\n",
    "                            continue                            \n",
    "                        else:\n",
    "                            mut_count = working_dict[sl][position_name]\n",
    "                            ix_mutant(position_name,mut_count,reads_mat,i,j)\n",
    "                            j = j + 1\n",
    "                            continue \n",
    "                    else:\n",
    "                        missing_mut.append(position_name)\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "            elif (i >= 80) and (i < 120): #SL3\n",
    "                sl = 'SL3' #sublibrary three\n",
    "                if (dhfr_nuc_wt[ione]+dhfr_nuc_wt[itwo]+dhfr_nuc_wt[ithree]) == codon_list[j]: #WILD TYPE!\n",
    "                    mut_count = working_dict[sl]['WT']\n",
    "                    ix_mutant(position_name,mut_count,reads_mat,i,j)\n",
    "                    j = j + 1\n",
    "                    continue    \n",
    "                else: #A and T should not show up in NNS mutations and are not counted\n",
    "                    if position_name in working_dict[sl].keys():\n",
    "                        if codon_list[j][-1] == 'A': #NNS filtering\n",
    "                            wrong_mut.append(position_name)\n",
    "                            j = j + 1\n",
    "                            continue\n",
    "                        elif codon_list[j][-1] == 'T': #NNS filtering\n",
    "                            wrong_mut.append(position_name)\n",
    "                            j = j + 1\n",
    "                            continue                            \n",
    "                        else:\n",
    "                            mut_count = working_dict[sl][position_name]\n",
    "                            ix_mutant(position_name,mut_count,reads_mat,i,j)\n",
    "                            j = j + 1\n",
    "                            continue \n",
    "                    else:\n",
    "                        missing_mut.append(position_name)\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "            elif (i >= 120) and (i < 159): #SL4\n",
    "                sl = 'SL4' #sublibrary four\n",
    "                if (dhfr_nuc_wt[ione]+dhfr_nuc_wt[itwo]+dhfr_nuc_wt[ithree]) == codon_list[j]: #WILD TYPE!\n",
    "                    mut_count = working_dict[sl]['WT']\n",
    "                    ix_mutant(position_name,mut_count,reads_mat,i,j)\n",
    "                    j = j + 1\n",
    "                    continue    \n",
    "                else: #A and T should not show up in NNS mutations and are not counted\n",
    "                    if position_name in working_dict[sl].keys():\n",
    "                        if codon_list[j][-1] == 'A':\n",
    "                            wrong_mut.append(position_name)\n",
    "                            j = j + 1\n",
    "                            continue\n",
    "                        elif codon_list[j][-1] == 'T':\n",
    "                            wrong_mut.append(position_name)\n",
    "                            j = j + 1\n",
    "                            continue                              \n",
    "                        else:\n",
    "                            mut_count = working_dict[sl][position_name]\n",
    "                            ix_mutant(position_name,mut_count,reads_mat,i,j)\n",
    "                            j = j + 1\n",
    "                            continue  \n",
    "                    else:\n",
    "                        missing_mut.append(position_name)\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "            else: #This should never be triggered. \n",
    "                print('something is wrong') #for error reporting. \n",
    "                j = j + 1\n",
    "                continue\n",
    "        i = i + 1    \n",
    "\n",
    "    nucleotide_matrix[condition] = reads_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the hamming distance between two 3 letter strings. \n",
    "It is given the string being compared and the reference one that the count is being adjusted from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HAMCALCULATOR(ham_calc_wt,ham_calc_compare):\n",
    "    ham_dist = 3 #starts off with the assumption they are tottaly different strings\n",
    "    for i in range(0, 3): #loops for each of the nucleotides\n",
    "        #if the nucleotide matches that being compared against, subtract one from the hamming distance\n",
    "        if ham_calc_wt[i] == ham_calc_compare[i]: \n",
    "            ham_dist = np.subtract(ham_dist, 1)\n",
    "        else:\n",
    "            continue\n",
    "    return(ham_dist)#this is a number 1,2,or 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the hard hamming filter. \n",
    "Hard refers to that the position being adjusted assumes all other counts are correct.\n",
    "This code section takes about 2 minutes to run. \n",
    "\n",
    "It iterates in the same way as before: We use I to signify each of the 159 amino acids of DHFR that have been mutated (all of them) and J to be the 64 different possible codons. Each wild type from each sublibrary has to be calculated separately. \n",
    "\n",
    "It loops through every codon in each timepoint and vial separately and calculates the number expected errant reads one could expect from another codon given:\n",
    "## \\begin{equation*} NErrant_t^{Mut} = N_t^{Wt}(-10^{(\\frac{\\bar{x}Q}{10})})^{HD} \\end{equation*}\n",
    "Where the number of errant mutants observed, $NErrant_t^{Mut}$  is equal to the number of observed wild type, $N_t^{Wt}$ (or any other mutant count being compared) multiplied by the probability that a base call is incorrect, $-10^{(\\frac{\\bar{x}Q}{10})}$ and raised to the power of the hamming distance, $HD$. \n",
    "\n",
    " The sum of $NErrant_t^{Mut}$ for every possible position is then subtracted from the actual mutant count. This is calculated for every possible mutation observed (the NNK mutants are not added to the nucleotide_matrix and thus do not contribute). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the hard hamming filter. It will make a new matrix of every position.\n",
    "#hard refers to that the position being adjusted assumes all other counts are correct.\n",
    "#This code section takes about 2 minutes to run. \n",
    "\n",
    "\n",
    "hamming_value = -4.0 #this is -1/10th the Illumina Q score average. (Or filtering value)\n",
    "#Genewiz (the sequencing company) reported an average Q score across all lanes + runs as Q40. \n",
    "hamming_count = 0 #sets the count as zero, the observed mutant count will be subtracted by hamming_count\n",
    "#to get the final adjusted count. \n",
    "hard_hamming_matrix = {} #creates a blank dictionary to store the hamming counts sorted by condition e.g. T6V2\n",
    "\n",
    "\n",
    "for condition in list(nucleotide_matrix.keys()): #37 of em. \n",
    "    #FOR WILD TYPE CALCULATION, which has to be done in blocks\n",
    "    wt_hamming_sl1 = data_dict[condition]['SL1']['WT']\n",
    "    wt_hamming_sl2 = data_dict[condition]['SL2']['WT']\n",
    "    wt_hamming_sl3 = data_dict[condition]['SL3']['WT']\n",
    "    wt_hamming_sl4 = data_dict[condition]['SL4']['WT']\n",
    "    I = 0 #amino acid position of DHFR\n",
    "    J = 0 #cycle through list of 3 letter nucleotides\n",
    "    while (I <= 158):\n",
    "        J = 0 \n",
    "        while (J <= 63):\n",
    "            hamming_count = 0\n",
    "            K = 0 #K is the iterator for every other position in that compare against\n",
    "            Ione = (np.multiply(I,3)) #these allow for grabbing wt codon from wt aa sequence position. \n",
    "            Itwo = (np.multiply(I,3) +1)\n",
    "            Ithree = (np.multiply(I,3) +2) \n",
    "            #check if the sequence is wild type, if so it is adjusted below. \n",
    "            #we have to cycle through every mutant that can contribute to an errant wild type\n",
    "            #which is every other mutant in the sublibrary, different than a mutation where we only consider\n",
    "            #the contributing reads at that codon.\n",
    "            if (dhfr_nuc_wt[Ione]+dhfr_nuc_wt[Itwo]+dhfr_nuc_wt[Ithree]) == codon_list[J]:\n",
    "                #WT SL1                   \n",
    "                if (I < 40): #SL1\n",
    "                    while (K <=63):\n",
    "                        if K == J :\n",
    "                            K = K + 1\n",
    "                            continue\n",
    "                        else:\n",
    "                            temp_hamming_count = 0\n",
    "                            hamming_number = HAMCALCULATOR(codon_list[K],codon_list[J])\n",
    "                            if hamming_number == 1 : #hamming number 1, value is 10^(Qscore/-10)\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          np.power(10,hamming_value))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 2 : #Hamming number of 2, values squared\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          (np.power(10,hamming_value) * np.power(10,hamming_value)))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 3 : #Hamming number of 3. Values cubed\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          (np.power(10,hamming_value) * np.power(10,hamming_value) * np.power(10,hamming_value)))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 0 :\n",
    "                                print('SOMETHING IS WRONG') #check to see if it is throwing in wild type for some reason. \n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                    #here we subtract the observed count from the estimated errant counts, producing the wt adjusted count.\n",
    "                    wt_hamming_sl1 = (wt_hamming_sl1 - hamming_count)\n",
    "                    J = J + 1\n",
    "                    continue\n",
    "                    \n",
    "                #WT SL2                     \n",
    "                elif (I >= 40) and (I < 80): #SL2\n",
    "                    while (K <=63):\n",
    "                        if K == J :\n",
    "                            K = K + 1\n",
    "                            continue\n",
    "                        else:\n",
    "                            temp_hamming_count = 0\n",
    "                            hamming_number = HAMCALCULATOR(codon_list[K],codon_list[J])\n",
    "                            if hamming_number == 1 : #hamming number 1, value is 10^(Qscore/-10)\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          np.power(10,hamming_value))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 2 : #Hamming number of 2, values squared\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          (np.power(10,hamming_value) * np.power(10,hamming_value)))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 3 : #Hamming number of 3. Values cubed\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          (np.power(10,hamming_value) * np.power(10,hamming_value) * np.power(10,hamming_value)))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 0 :\n",
    "                                print('SOMETHING IS WRONG') #check to see if it is throwing in wild type for some reason. \n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                    #here we subtract the observed count from the estimated errant counts, producing the wt adjusted count.\n",
    "                    wt_hamming_sl2 = (wt_hamming_sl2 - hamming_count)\n",
    "                    J = J + 1\n",
    "                    continue                                       \n",
    "                #WT SL3                       \n",
    "                elif (I >= 80) and (I < 120): #SL3\n",
    "                    while (K <=63):\n",
    "                        if K == J :\n",
    "                            K = K + 1\n",
    "                            continue\n",
    "                        else:\n",
    "                            temp_hamming_count = 0\n",
    "                            hamming_number = HAMCALCULATOR(codon_list[K],codon_list[J])\n",
    "                            if hamming_number == 1 : #hamming number 1, value is 10^(Qscore/-10)\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          np.power(10,hamming_value))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 2 : #Hamming number of 2, values squared\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          (np.power(10,hamming_value) * np.power(10,hamming_value)))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 3 : #Hamming number of 3. Values cubed\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          (np.power(10,hamming_value) * np.power(10,hamming_value) * np.power(10,hamming_value)))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 0 :\n",
    "                                print('SOMETHING IS WRONG') #check to see if it is throwing in wild type for some reason. \n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                    #here we subtract the observed count from the estimated errant counts, producing the wt adjusted count.\n",
    "                    wt_hamming_sl3 = (wt_hamming_sl3 - hamming_count)\n",
    "                    J = J + 1\n",
    "                    continue                                              \n",
    "                #WT SL4                     \n",
    "                elif (I >= 120) and (I < 159): #SL4\n",
    "                    while (K <=63):\n",
    "                        if K == J :\n",
    "                            K = K + 1\n",
    "                            continue\n",
    "                        else:\n",
    "                            temp_hamming_count = 0\n",
    "                            hamming_number = HAMCALCULATOR(codon_list[K],codon_list[J])\n",
    "                            if hamming_number == 1 : #hamming number 1, value is 10^(Qscore/-10)\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          np.power(10,hamming_value))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 2 : #Hamming number of 2, values squared\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          (np.power(10,hamming_value) * np.power(10,hamming_value)))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 3 : #Hamming number of 3. Values cubed\n",
    "                                temp_hamming_count = (nucleotide_matrix[condition][I,K] * \\\n",
    "                                                          (np.power(10,hamming_value) * np.power(10,hamming_value) * np.power(10,hamming_value)))\n",
    "                                hamming_count = (hamming_count + temp_hamming_count)\n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                            elif hamming_number == 0 :\n",
    "                                print('SOMETHING IS WRONG') #check to see if it is throwing in wild type for some reason. \n",
    "                                K = K + 1\n",
    "                                continue\n",
    "                    #here we subtract the observed count from the estimated errant counts, producing the wt adjusted count.\n",
    "                    wt_hamming_sl4 = (wt_hamming_sl4 - hamming_count)\n",
    "                    J = J + 1\n",
    "                    continue                       \n",
    "            #NOT WT\n",
    "            else:#not wild type\n",
    "                J = J + 1\n",
    "                continue\n",
    "        I = I + 1\n",
    "                   \n",
    "    #END WILD TYPE CALCULATIONS, now onto the mutations:       \n",
    "    hamming_array = np.zeros(shape = [len(dhfr_wt_ix),len(codon_list)])\n",
    "    i = 0 # Down the matrix (dhfr_wt) 0-158\n",
    "    j = 0 # Across the matrix (nucleotides) 0-63\n",
    "    while (i <= 158):\n",
    "        j = 0\n",
    "        while (j <= 63):\n",
    "            hamming_count = 0\n",
    "            k = 0 #k is the iterator for every other position in that compare against\n",
    "            ione = (np.multiply(i,3)) #these allow for grabbing wt codon from wt aa sequence position. \n",
    "            itwo = (np.multiply(i,3) +1)\n",
    "            ithree = (np.multiply(i,3) +2)        \n",
    "            #this gives the name in the directory to look up, may not use here\n",
    "            position_name = (dhfr_nuc_wt[ione]+dhfr_nuc_wt[itwo]+dhfr_nuc_wt[ithree]+str((i+1))+codon_list[j])\n",
    "            \n",
    "           #check if we hit a wild type in this loop.\n",
    "            if (dhfr_nuc_wt[ione]+dhfr_nuc_wt[itwo]+dhfr_nuc_wt[ithree]) == codon_list[j]: #WILD TYPE!\n",
    "                if (i < 40): #SL1\n",
    "                    hamming_array[i,j] = wt_hamming_sl1 #calculated above\n",
    "                    j = j + 1\n",
    "                    continue\n",
    "                elif (i >= 40) and (i < 80): #SL2\n",
    "                    hamming_array[i,j] = wt_hamming_sl2 #calculated above\n",
    "                    j = j + 1\n",
    "                    continue\n",
    "                elif (i >= 80) and (i < 120): #SL3\n",
    "                    hamming_array[i,j] = wt_hamming_sl3 #calculated above\n",
    "                    j = j + 1\n",
    "                    continue\n",
    "                elif (i >= 120) and (i < 159): #SL4\n",
    "                    hamming_array[i,j] = wt_hamming_sl4 #calculated above\n",
    "                    j = j + 1\n",
    "                    continue\n",
    "            else: #not wild type\n",
    "                while (k <=63):\n",
    "                    if k == j : #this prevents including a mutant's own count in its hamming adjustment\n",
    "                        k = k + 1\n",
    "                        continue\n",
    "                    else: \n",
    "                    #implement hamming filtering. \n",
    "                        temp_hamming_count = 0\n",
    "                        hamming_number = HAMCALCULATOR(codon_list[k],codon_list[j])\n",
    "                        if hamming_number == 1 : #hamming number 1, value is 10^(Qscore/-10)\n",
    "                            temp_hamming_count = (nucleotide_matrix[condition][i,k] * \\\n",
    "                                                      np.power(10,hamming_value))\n",
    "                            hamming_count = (hamming_count + temp_hamming_count)\n",
    "                            k = k + 1\n",
    "                            continue\n",
    "                        elif hamming_number == 2 : #Hamming number of 2, values squared\n",
    "                            temp_hamming_count = (nucleotide_matrix[condition][i,k] * \\\n",
    "                                                      (np.power(10,hamming_value) * np.power(10,hamming_value)))\n",
    "                            hamming_count = (hamming_count + temp_hamming_count)\n",
    "                            k = k + 1\n",
    "                            continue\n",
    "                        elif hamming_number == 3 : #Hamming number of 3. Values cubed\n",
    "                            temp_hamming_count = (nucleotide_matrix[condition][i,k] * \\\n",
    "                                                      (np.power(10,hamming_value) * np.power(10,hamming_value) * np.power(10,hamming_value)))\n",
    "                            hamming_count = (hamming_count + temp_hamming_count)\n",
    "                            k = k + 1\n",
    "                            continue\n",
    "                        elif hamming_number == 0 :\n",
    "                            print('SOMETHING IS WRONG') #check to see if it is throwing in wild type for some reason. \n",
    "                            k = k + 1\n",
    "                            continue\n",
    "                #here we make sure that we dont set a negative mutant count. \n",
    "                if (nucleotide_matrix[condition][i,j] - hamming_count) < 0 :\n",
    "                    hamming_array[i,j] = 0\n",
    "                else:\n",
    "                    #here we subtract the observed count from the estimated errant counts, producing the adjusted count.\n",
    "                    hamming_array[i,j] = (nucleotide_matrix[condition][i,j] - hamming_count)\n",
    "                hamming_count = 0\n",
    "                j = j + 1\n",
    "                continue\n",
    "        i = i + 1       \n",
    "    #After looping though every possible mutation in DHFR we then save the array and advance to the next condition.        \n",
    "    hard_hamming_matrix[condition] = hamming_array\n",
    "    #sorry about all the loops. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function allows for translating the codon into single letter protein code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the DNA into protein\n",
    "def translate_seq(seq):\n",
    "    seq = Seq(seq,generic_dna) #using the Seq function from Bio.Seq\n",
    "    seq_translate = str(seq.translate().strip())\n",
    "    return seq_translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to write mutant counts into a .txt file located in ./output/ for each condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutputFile_aa(outName):\n",
    "    #outName is the condition, e.g. T1V1 (for timepoint 1, vial 1)\n",
    "    output_file = open('output/'+outName+'hard_adjusted_residue'+'.txt','w') \n",
    "    #write out mutant counts \n",
    "    for sl in aa_counts.keys():\n",
    "        for key in aa_counts[sl].keys():\n",
    "            #this produces a tab separated list of the sublibrary, the mutant, and the count\n",
    "            #e.g. SL1 /t M1A /t 2770.0\n",
    "            output_file.write(sl+'\\t'+key+'\\t'+str(aa_counts[sl][key])+'\\n')\n",
    "\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert the sets of nucleotides into aminio acids, combine the ones that had multiple codons, round them to a whole number, and then save the file out for each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save out hard hamming matrix\n",
    "for condition in list(hard_hamming_matrix.keys()): #37 conditions.       \n",
    "    aa_counts = {'SL1':{},'SL2':{},'SL3':{},'SL4':{}}\n",
    "    i = 0 # Down the matrix (dhfr_wt) 0-158\n",
    "    j = 0 # Across the matrix (nucleotides) 0-63\n",
    "    while (i <= 158):\n",
    "        j = 0\n",
    "        while (j <= 63):\n",
    "            ione = (np.multiply(i,3)) #these allow for grabbing wt codon from wt aa sequence position. \n",
    "            itwo = (np.multiply(i,3) +1)\n",
    "            ithree = (np.multiply(i,3) +2)        \n",
    "            #this gives the name in the directory to look up, may not use here\n",
    "            position_name = (dhfr_nuc_wt[ione]+dhfr_nuc_wt[itwo]+dhfr_nuc_wt[ithree]+str((i+1))+codon_list[j])\n",
    "            \n",
    "            ####### WILD TYPE#######\n",
    "            if (dhfr_nuc_wt[ione]+dhfr_nuc_wt[itwo]+dhfr_nuc_wt[ithree]) == codon_list[j]: #True_WILD TYPE!\n",
    "                if (i < 40): #SL1\n",
    "                    sl = 'SL1'\n",
    "                    if 'WT' in aa_counts[sl].keys():\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        aa_counts[sl]['WT'] = round(hard_hamming_matrix[condition][i,j])\n",
    "                    j = j + 1\n",
    "                    continue\n",
    "                elif (i >= 40) and (i < 80): #SL2\n",
    "                    sl = 'SL2'\n",
    "                    if 'WT' in aa_counts[sl].keys():\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        aa_counts[sl]['WT'] = round(hard_hamming_matrix[condition][i,j])\n",
    "                    j = j + 1\n",
    "                    continue\n",
    "                elif (i >= 80) and (i < 120): #SL3\n",
    "                    sl = 'SL3'\n",
    "                    if 'WT' in aa_counts[sl].keys():\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        aa_counts[sl]['WT'] = round(hard_hamming_matrix[condition][i,j])\n",
    "                    j = j + 1\n",
    "                    continue\n",
    "                elif (i >= 120) and (i < 159): #SL4\n",
    "                    sl = 'SL4'\n",
    "                    if 'WT' in aa_counts[sl].keys():\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        aa_counts[sl]['WT'] = round(hard_hamming_matrix[condition][i,j])\n",
    "                    j = j + 1\n",
    "                    continue\n",
    "            else: #not wild type\n",
    "                wild_type = translate_seq(dhfr_nuc_wt[ione]+dhfr_nuc_wt[itwo]+dhfr_nuc_wt[ithree])\n",
    "                residue_name = translate_seq(codon_list[j])\n",
    "                aa_position_name = (wild_type+str((i+1))+residue_name)\n",
    "                if wild_type == residue_name:\n",
    "                    aa_position_name =  'SNEAKY_WT' #this catches mutations that are just turned into WT\n",
    "                if (i < 40): #SL1\n",
    "                    sl = 'SL1'\n",
    "                    if aa_position_name in aa_counts[sl].keys():\n",
    "                        aa_counts[sl][aa_position_name] +=round(hard_hamming_matrix[condition][i,j])\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        aa_counts[sl][aa_position_name] = round(hard_hamming_matrix[condition][i,j])\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                elif (i >= 40) and (i < 80): #SL2\n",
    "                    sl = 'SL2'\n",
    "                    if aa_position_name in aa_counts[sl].keys():\n",
    "                        aa_counts[sl][aa_position_name] +=round(hard_hamming_matrix[condition][i,j])\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        aa_counts[sl][aa_position_name] = round(hard_hamming_matrix[condition][i,j])\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                elif (i >= 80) and (i < 120): #SL3\n",
    "                    sl = 'SL3'\n",
    "                    if aa_position_name in aa_counts[sl].keys():\n",
    "                        aa_counts[sl][aa_position_name] +=round(hard_hamming_matrix[condition][i,j])\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        aa_counts[sl][aa_position_name] = round(hard_hamming_matrix[condition][i,j])\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                elif (i >= 120) and (i < 159): #SL4\n",
    "                    sl = 'SL4'\n",
    "                    if aa_position_name in aa_counts[sl].keys():\n",
    "                        aa_counts[sl][aa_position_name] +=round(hard_hamming_matrix[condition][i,j])\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        aa_counts[sl][aa_position_name] = round(hard_hamming_matrix[condition][i,j])\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "\n",
    "        i = i + 1\n",
    "            \n",
    "    writeOutputFile_aa(condition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
